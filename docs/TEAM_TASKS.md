# チームタスク割り当て

本ドキュメントは、**Air-Visualizer** プロジェクトを PoC から MVP へと進めるための、各チームメンバーの具体的なタスクをまとめたものです。

## 📂 バックエンドディレクトリ構成案 (担当: メンバーB)
モジュール性を確保するため、`backend/` ディレクトリを以下のように構成してください：

```
backend/
├── app/
│   ├── __init__.py
│   ├── main.py              # FastAPI エントリーポイント
│   ├── core/                # コア設定
│   │   └── config.py
│   ├── websockets/          # WebSocket ハンドリング
│   │   ├── manager.py       # 接続マネージャー
│   │   └── router.py
│   ├── services/            # ビジネスロジック
│   │   ├── analysis/        # メンバーCの担当領域
│   │   │   ├── sentiment.py
│   │   │   └── audio.py
│   │   └── coaching/        # メンバーDの担当領域
│   │       └── llm.py
│   └── models/              # DBモデル (SQLite)
│       └── session.py
├── requirements.txt
└── .env
```

---

## 👤 メンバーA：フロントエンド & UI (蓮沼)
**注力領域**: ユーザーインターフェース & データ抽出

### タスク
1. **`Popup.tsx` UIの強化**
   - **ゴール**: システムの状態と「場の空気」を可視化するダッシュボードを作成する。
   - **機能**:
     - **接続ステータス**: WebSocketの接続状態を示すインジケーター（緑/赤）。
     - **「空気」メーター**: 会議の現在の「空気（感情）」を表すゲージや動的なビジュアル（例：「緊迫」から「和やか」まで）。
     - **デバッグログ**: （任意）検証用に抽出された字幕を表示するスクロールエリア。
   - **技術**: React, Tailwind CSS (または通常のCSS)。

2. **DOM監視の改善 (`meet-observer.tsx`)**
   - Google Meetのクラス名が変更されても安定して字幕を抽出できるよう、`MutationObserver` ロジックを改善し続ける。
   - 可能であれば、起動時にバックエンドの Config API (`GET /config`) からCSSセレクタを取得し、拡張機能の更新なしで修正を適用できるようにする。

---

## 👤 メンバーB：バックエンド & アーキテクチャ (本多)
**注力領域**: システムの安定性 & データパイプライン

### タスク
1. **FastAPI プロジェクト構造の再構築**
   - 現在の単一ファイル `main.py` を、上記のモジュール構成にリファクタリングする。
   - 新しい構造で `uvicorn` がスムーズに動作することを確認する。

2. **WebSocket マネージャー (`websockets/manager.py`)**
   - 堅牢な `ConnectionManager` クラスを実装する。
   - `connect`、`disconnect`、`broadcast` イベントを適切に処理する。
   - **データパイプライン**: フロントエンドからデータが届いた時の処理フロー:
     - 生ログを SQLite に保存 (非同期)。
     - テキストを **分析サービス** (メンバーC) へ渡す。
     - 分析結果が特定の条件を満たした場合、**コーチングサービス** (メンバーD) へ渡す。
     - 結果を WebSocket 経由でフロントエンドに返す。

---

## 👤 メンバーC：AI/MLエンジニア (森)
**注力領域**: 感情 & 音声分析

### タスク
1. **感情分析モジュール (`services/analysis/sentiment.py`)**
   - 関数 `analyze_sentiment(text: str) -> dict` を作成する。
   - **モデル**: 軽量な日本語BERTモデル（例: `cl-tohoku/bert-base-japanese-v3` や `wrime` で学習済みのモデル）を使用する。
   - **出力**: `{"score": float (-1.0 to 1.0), "label": "negative"|"neutral"|"positive"}`。
   - *注意*: 推論速度を重視する。GPUが利用できない場合はCPUでの動作を考慮する。

2. **音声特徴抽出 (`services/analysis/audio.py`)**
   - 関数 `analyze_audio(audio_bytes: bytes) -> dict` を作成する。
   - **ツール**: `librosa` または `numpy`。
   - **指標**: **音量** (RMS) と **ピッチ** (基本周波数) を抽出する。
   - **ロジック**: 大音量 ＋ 高ピッチ は「興奮」や「怒り」を示唆する可能性がある。

---

## 👤 メンバーD：LLM & コーチング (石橋)
**注力領域**: コーチングロジック & プロンプトエンジニアリング

### タスク
1. **LLM サービス (`services/coaching/llm.py`)**
   - OpenAI API (または互換インターフェース) を統合する。
   - 関数 `generate_coaching(context: list, current_sentiment: dict) -> str` を作成する。

2. **プロンプトエンジニアリング**
   - 「コミュニケーションコーチ」として振る舞うシステムプロンプトを設計する。
   - **入力**: 直近の5発言 ＋ 感情スコア。
   - **出力**: 短く、実践的なアドバイス（例：「相手が少し引いています。'なるほど'と一度受け止めましょう」）。
   - **制約**: アドバイスは、感情が **ネガティブ** または **緊迫** している場合にのみ生成する。

3. **トリガーロジック**
   - コスト削減とユーザーへの過干渉を防ぐため、LLMを呼び出す閾値を定義する。
   - 例: `if sentiment_score < -0.5 and last_advice_time > 30s`。
